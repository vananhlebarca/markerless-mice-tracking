{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markerless Mice Tracking for Social Experiments\n",
    "This is an implementation of the pipeline described in the paper. \n",
    "* Input of the pipeline can be a video or a directory containing frames in sequence. \n",
    "* Output of the workflow are two csv files storing coordinates of snout and tailbase of corresponding to two mice: *features_mouse1_ensemble.csv* and *features_mouse2_ensemble.csv*\n",
    "    \n",
    "\n",
    "This pipeline used a pretrained Mask-RCNN model and a pretrained DeepLabCut model provided in subfolders mrcnn_models and dlc_models. However, Mask-RCNN and DeepLabCut models should be retrained on new data if the settings of new videos are different with our setting in the paper. The code to train those models can be found in two Jupyter Notebooks as follows:\n",
    "* *deeplabcut_training.ipynb*\n",
    "* *mrcnn_training.ipynb*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "from mouse.utils import labelmejson_to_png\n",
    "from mouse.utils import video2frames, background_subtraction\n",
    "from mouse.utils import correct_segmentation_errors, mouse_mrcnn_segmentation\n",
    "from mouse.utils import tracking_inference, mask_based_detection, mice_separation\n",
    "from mouse.utils import deeplabcut_detection, ensemble_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to cage background which is normally imaged before the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_dir='..\\\\videos\\\\BG1.jpg'                                       #----------------update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path the a new video or frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to a new video \n",
    "tracking_video_dir = \"..\\\\videos\\\\video1.avi\"                            #----------------update\n",
    "\n",
    "# Extracting the video into frames \n",
    "print('The video will be extracted into frames stored in {}'.format(os.path.splitext(tracking_video_dir)[0] + '\\\\images'))\n",
    "video2frames(tracking_video_dir)  \n",
    "frames_dir = os.path.join(os.path.splitext(tracking_video_dir)[0], 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frames\n",
    "#frames_dir = '..\\\\videos\\\\video4\\images'                                 #-------------------update if input are frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Conventional foreground detection to segment mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = background_subtraction(frames_dir, background_dir)\n",
    "\n",
    "#components = '../videos/video1/components.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Mask-RCNN to segment mice in the failed frames in step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"mrcnn_models\")\n",
    "\n",
    "# Directory to load weights of a model. If MODEL_PATH=None, the latest weights in MODEL_DIR will be loaded\n",
    "MODEL_PATH = \"..\\\\mrcnn_models\\\\mask_rcnn_mouse_0025.h5\"                        #------------Update if a new model is used\n",
    "\n",
    "components = mouse_mrcnn_segmentation(components, frames_dir, background_dir, model_dir=MODEL_DIR, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Suggesting intervention\n",
    "Althought we did not intervene the Mask-RCNN results in the paper, it is recommended to fix very 3 consecutive failed frames. \n",
    "Skip step 3 if you don't want to correct the mistakes.\n",
    "\n",
    "To correct segmentation errors, in Labelme GUI open *fix_dir* and annotate both mice as a label of *mouse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_dir = os.path.join(os.path.dirname(frames_dir), 'suggested_fix')\n",
    "os.mkdir(fix_dir)\n",
    "\n",
    "suggesting_correction = correct_segmentation_errors(components, fix_dir, frames_dir)\n",
    "\n",
    "if suggesting_correction==0:\n",
    "    print('There are no frames for correcting')\n",
    "else:\n",
    "    print('{} frames in the directory {} are recommended to be corrected using Labelme'.format(suggesting_correction, fix_dir))\n",
    "    ! labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert fix_frames back to FG and update components\n",
    "output_dir = os.path.join(os.path.dirname(frames_dir),'FG')        \n",
    "labelmejson_to_png(fix_dir, output_dir)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Tracking inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_dir = os.path.join(os.path.dirname(frames_dir),'FG')\n",
    "tracking_inference(fg_dir, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Mask-based detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_dir = os.path.join(os.path.dirname(frames_dir),'tracking')\n",
    "features_mouse1_md, features_mouse2_md = mask_based_detection(tracking_dir, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Deeplabcut detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separating the video into 2 videos corresponding to two animals.\n",
    "mice_separation(tracking_dir, frames_dir, background_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detect the key points by Deeplabcut model\n",
    "config_dir = '../dlc_models/Tracking-Vananh-2019-08-13/config.yaml'              #------Update this for your own model\n",
    "\n",
    "video_dir = [os.path.join(os.path.dirname(tracking_dir), 'mouse1.avi'),\n",
    "             os.path.join(os.path.dirname(tracking_dir), 'mouse2.avi')]\n",
    "\n",
    "features_mouse1_dlc, features_mouse2_dlc = deeplabcut_detection(config_dir, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7:  Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mouse1_ensemble = ensemble_features(features_mouse1_md, features_mouse1_dlc, tracking_dir, mouse_id=1)    \n",
    "features_mouse2_ensemble = ensemble_features(features_mouse2_md, features_mouse2_dlc, tracking_dir, mouse_id=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
